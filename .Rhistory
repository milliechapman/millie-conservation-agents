import gym
import gym_conservation
from stable_baselines3 import A2C
from stable_baselines3.common.env_util import make_vec_env
# Parallel environments
env = gym.make("conservation-v5")
model = A2C("MlpPolicy", env, verbose=1)
model.learn(total_timesteps=25000)
model.save("a2c_cartpole")
model = A2C("MlpPolicy", env, verbose=1)
model.learn(total_timesteps=1000)
model.save("conservation-v5-A2C-millie")
from stable_baselines3.common.evaluation import evaluate_policy
from stable_baselines3.common.monitor import Monitor
score = evaluate_policy(model, Monitor(env), n_eval_episodes=10)
score
eval_env = Monitor(gym.make("conservation-v5"))
score = evaluate_policy(model, Monitor(env), n_eval_episodes=10)
score
import gym
import gym_conservation
from stable_baselines3 import A2C
from stable_baselines3.common.env_util import make_vec_env
from stable_baselines3.common.evaluation import evaluate_policy
from stable_baselines3.common.monitor import Monitor
env = make_vec_env("conservation-v5", n=4)
env = make_vec_env("conservation-v5", n_envs=4)
model = A2C("MlpPolicy", env, verbose=1, tensorboard_log = "/var/log/tensorboard/millie")
model.learn(total_timesteps=25000)
model.learn(total_timesteps=25000)
reticulate::repl_python()
